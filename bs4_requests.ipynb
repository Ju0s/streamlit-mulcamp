{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91d32a3-71a0-4a00-9fc7-ac49e7ab9d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.31.0\n",
      "4.12.3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "print(requests.__version__)\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d65007-399f-4129-9b62-fd351508d71c",
   "metadata": {},
   "source": [
    "## 네이버 상태 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9933da94-112a-4fdf-a4be-20237d1c24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.naver.com/'\n",
    "\n",
    "req = requests.get(URL)\n",
    "print(req.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339c2c14-4290-4cab-bf26-7c992a6a51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c4f8fe3-d0cf-4d91-9ea9-693331413229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>애플</li>, <li>삼성</li>, <li>노키아</li>, <li>LG</li>]\n",
      "['애플', '삼성', '노키아', 'LG']\n",
      "   회사명\n",
      "0   애플\n",
      "1   삼성\n",
      "2  노키아\n",
      "3   LG\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "with open('index.html', 'r', encoding='UTF8') as f:\n",
    "\n",
    "    # step 01: 데이터 수집\n",
    "    contents = f.read()\n",
    "\n",
    "    # step 02: 데이터 파싱 (순수한 HTML 파일을 BeaurifulSoup 객체로 변환)\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    # print(soup)\n",
    "    # print(soup.h2)\n",
    "    # print(soup.ul)\n",
    "    # print(\"-----\")\n",
    "    # print(soup.ul.li)\n",
    "    # 4개의 li 태그에 있는 회사명 모두 가져오기\n",
    "\n",
    "    # step 03: 데이터 수집을 위한 특정 태그 찾기\n",
    "    print(soup.find_all('li'))\n",
    "    companies = []\n",
    "\n",
    "    # step 04: 데이터 가공\n",
    "    for tag in soup.find_all('li'):\n",
    "        companies.append(tag.text)\n",
    "    print(companies)\n",
    "\n",
    "    # step 05: 처리된 데이터 저장 - pandas 데이터프레임\n",
    "    crawling_dict = {'회사명': companies}\n",
    "    result = pd.DataFrame(crawling_dict)\n",
    "    print(result)\n",
    "\n",
    "    # step 06: csv 파일로 내보내기 or DB로 내보내기\n",
    "    # result.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013dfcf6-7e49-46e4-a1d8-744b27274ab0",
   "metadata": {},
   "source": [
    "## 벅스 차트 노래 제목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca8f88f4-76df-4eea-973f-5ab17a37ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           노래제목\n",
      "0                 Love wins all\n",
      "1                          Wife\n",
      "2                         To. X\n",
      "3                      Love 119\n",
      "4                          에피소드\n",
      "..                          ...\n",
      "95  머물러주오 (Prod. 안신애 & Philtre)\n",
      "96                       운이 좋았지\n",
      "97                      Snowman\n",
      "98                Cool With You\n",
      "99         사랑은 먼 길을 돌아온 메아리 같아서\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "\n",
    "def crawling(soup) :\n",
    "    # print(soup)\n",
    "    tbody = soup.find(\"tbody\")\n",
    "    result = []\n",
    "    for p in tbody.find_all('p', class_ = 'title'):\n",
    "        result.append(p.get_text().strip())\n",
    "    return result\n",
    "\n",
    "def main() :\n",
    "    custom_header = {\n",
    "        'referer' : 'https://music.bugs.co.kr/',\n",
    "        'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    url = \"https://music.bugs.co.kr/chart\" # 크롤링 하려는 웹사이트\n",
    "    req = requests.get(url, headers = custom_header)\n",
    "    \n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    crawling(soup)\n",
    "\n",
    "    titles = crawling(soup)\n",
    "    print(pd.DataFrame({\"노래제목\" : titles}))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58c620-2b28-4041-831b-b73fc4202719",
   "metadata": {},
   "source": [
    "## 삼성전자 증권 시세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f444eaf-c1fd-4aa5-9c7a-32692c68bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "company_code = '005930' # 삼성전자\n",
    "    \n",
    "headers = { \n",
    "             'referer' : 'https://finance.naver.com/item/sise.naver?code=005930',\n",
    "             'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "            }\n",
    "N = 12\n",
    "df = None\n",
    "for pageNum in range(1, N+1):\n",
    "    url =f'https://finance.naver.com/item/sise_day.naver?code=005930&page={pageNum}'\n",
    "    req = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "    result = pd.read_html(req.text, encoding='euc-kr')[0]\n",
    "    #print(result)\n",
    "    df = pd.concat([df, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7526ad1-bdeb-4ab3-9df3-eac4456c7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f082dbf-0d08-4ce9-9a29-3e5fd29dbda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>종가</th>\n",
       "      <th>전일비</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>거래량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024.01.31</td>\n",
       "      <td>72700.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>73400.0</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>72500.0</td>\n",
       "      <td>13080752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024.01.30</td>\n",
       "      <td>74300.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>75300.0</td>\n",
       "      <td>73700.0</td>\n",
       "      <td>12244418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024.01.29</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>73800.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>73500.0</td>\n",
       "      <td>13976521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024.01.26</td>\n",
       "      <td>73400.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>73700.0</td>\n",
       "      <td>74500.0</td>\n",
       "      <td>73300.0</td>\n",
       "      <td>11160062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024.01.25</td>\n",
       "      <td>74100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74200.0</td>\n",
       "      <td>74800.0</td>\n",
       "      <td>73700.0</td>\n",
       "      <td>11737747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2023.08.10</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>68300.0</td>\n",
       "      <td>68500.0</td>\n",
       "      <td>67800.0</td>\n",
       "      <td>10227311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2023.08.09</td>\n",
       "      <td>68900.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>69600.0</td>\n",
       "      <td>67900.0</td>\n",
       "      <td>17259673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2023.08.08</td>\n",
       "      <td>67600.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>67400.0</td>\n",
       "      <td>14664709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2023.08.07</td>\n",
       "      <td>68500.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>67700.0</td>\n",
       "      <td>69200.0</td>\n",
       "      <td>67600.0</td>\n",
       "      <td>10968505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2023.08.04</td>\n",
       "      <td>68300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>68800.0</td>\n",
       "      <td>69100.0</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>12360193.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             날짜       종가     전일비       시가       고가       저가         거래량\n",
       "1    2024.01.31  72700.0  1600.0  73400.0  74000.0  72500.0  13080752.0\n",
       "2    2024.01.30  74300.0   100.0  75000.0  75300.0  73700.0  12244418.0\n",
       "3    2024.01.29  74400.0  1000.0  73800.0  75200.0  73500.0  13976521.0\n",
       "4    2024.01.26  73400.0   700.0  73700.0  74500.0  73300.0  11160062.0\n",
       "5    2024.01.25  74100.0   100.0  74200.0  74800.0  73700.0  11737747.0\n",
       "..          ...      ...     ...      ...      ...      ...         ...\n",
       "174  2023.08.10  68000.0   900.0  68300.0  68500.0  67800.0  10227311.0\n",
       "175  2023.08.09  68900.0  1300.0  68000.0  69600.0  67900.0  17259673.0\n",
       "176  2023.08.08  67600.0   900.0  69000.0  69100.0  67400.0  14664709.0\n",
       "177  2023.08.07  68500.0   200.0  67700.0  69200.0  67600.0  10968505.0\n",
       "178  2023.08.04  68300.0   500.0  68800.0  69100.0  68200.0  12360193.0\n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d676242f-4abf-471c-99d0-d0595a097d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             날짜       종가     전일비       시가       고가       저가         거래량\n",
      "0    2024.01.31  72700.0  1600.0  73400.0  74000.0  72500.0  13080752.0\n",
      "1    2024.01.30  74300.0   100.0  75000.0  75300.0  73700.0  12244418.0\n",
      "2    2024.01.29  74400.0  1000.0  73800.0  75200.0  73500.0  13976521.0\n",
      "3    2024.01.26  73400.0   700.0  73700.0  74500.0  73300.0  11160062.0\n",
      "4    2024.01.25  74100.0   100.0  74200.0  74800.0  73700.0  11737747.0\n",
      "..          ...      ...     ...      ...      ...      ...         ...\n",
      "115  2023.08.10  68000.0   900.0  68300.0  68500.0  67800.0  10227311.0\n",
      "116  2023.08.09  68900.0  1300.0  68000.0  69600.0  67900.0  17259673.0\n",
      "117  2023.08.08  67600.0   900.0  69000.0  69100.0  67400.0  14664709.0\n",
      "118  2023.08.07  68500.0   200.0  67700.0  69200.0  67600.0  10968505.0\n",
      "119  2023.08.04  68300.0   500.0  68800.0  69100.0  68200.0  12360193.0\n",
      "\n",
      "[120 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "def crawling(url, headers, soup):\n",
    "    last_page = int(soup.select_one('td.pgRR').a['href'].split('=')[-1])\n",
    "    \n",
    "    df = None\n",
    "    count = 0\n",
    "    for page in range(1, last_page + 1):\n",
    "      req = requests.get(f'{url}&page={page}', headers=headers)\n",
    "      df = pd.concat([df, pd.read_html(req.text, encoding = \"euc-kr\")[0]], ignore_index=True)\n",
    "      if count > 10:\n",
    "        break\n",
    "      count += 1\n",
    "      time.sleep( random.uniform(2,4)) \n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    company_code = '005930' # 삼성전자\n",
    "    url =\"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code\n",
    "    \n",
    "    headers = { \n",
    "             'referer' : 'https://finance.naver.com/item/sise.naver?code=005930',\n",
    "             'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "            }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    result = crawling(url, headers, soup)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
